---
title: "mice_work_flow"
author: "Adam A. Bramlett"
date: "2024-02-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(readr)
library(lme4) 
library(dplyr) 
library(forcats)   
library(broom.mixed)  
    
```

this code is for combining raw data. If you are interested in simply running the data please skip this and move forward to line 130 and start from there.
```{r,eval = Sys.info()[["user"]] == "nadambramlett",warning=FALSE}
# General function to read and combine CSV files from a list of directories based on a pattern
combine_files_by_pattern <- function(directories, pattern) {
  # Initialize an empty list to store the combined data from each directory
  all_data <- list()

  # Loop through each directory
  for (dir in directories) {
    # Get the list of files in the directory that match the pattern
    files <- list.files(dir, pattern = pattern, full.names = TRUE)
    
    # Read and combine all filtered CSV files in the directory
    combined_data <- bind_rows(lapply(files, function(file) {
      data <- read_csv(file)
      # Optionally, add a source file column
      data$source_file <- basename(file)
      return(data)
    }))
    
    # Replace spaces in column names with dots
    colnames(combined_data) <- gsub(" ", ".", colnames(combined_data))
    
    # Add the combined data to the list
    all_data <- append(all_data, list(combined_data))
  }

  # Combine all data into a single dataframe
  final_data <- bind_rows(all_data)
  
  return(final_data)
}

# Define the base path
path <- "../extension_data"

# List of subdirectories within the base path
directories <- c(
  paste0(path, "/data_exp_187631-v4/"),#japanese
  paste0(path, "/data_exp_187633-v4/"),#mandarin
  #paste0(path, "/data_exp_187632-v4/"),
  paste0(path, "/data_exp_187630-v3/")#minnan
  #,paste0(path, "/data_exp_187747-v3/")#mandarin version 2 with longer words
)

test_data <- combine_files_by_pattern(directories, "31k6|77al")
train_data <- combine_files_by_pattern(directories, "ci6a|rkna|3ud8|4nzj")
quest_data <- combine_files_by_pattern(directories, "iali")

write.csv(test_data, "../data_syb/test_data_extension.csv", row.names = FALSE)
write.csv(train_data, "../data_syb/train_data_extension.csv", row.names = FALSE)
write.csv(quest_data, "../data_syb/quest_extension.csv", row.names = FALSE)
```

```{r,eval = Sys.info()[["user"]] == "padambramlett"},warning=FALSE}
#### et data
library(readxl)
# Function to read and combine Excel files from 'uploads' subfolders across directories based on a pattern
combine_et_files_by_pattern <- function(directories, pattern) {
  # Initialize an empty list to store the combined data from each directory
  all_data <- list()

  # Loop through each directory
  for (dir in directories) {
    # Define the path to the 'uploads' subfolder
    upload_path <- file.path(dir, "uploads")
    
    # Get the list of files in the 'uploads' subfolder that match the pattern
    files <- list.files(upload_path, pattern = pattern, full.names = TRUE)
    
    # Read and process each Excel file
    list_of_data_frames <- lapply(files, function(file) {
      et_data <- read_excel(file)
      et_data$et_file <- basename(file)
      return(et_data)
    })
    
    # Combine the list of data frames into one data frame
    combined_data <- do.call(rbind, list_of_data_frames)
    
    # Perform the necessary data transformations
    combined_data <- combined_data %>%
      mutate(Participant.Private.ID = participant_id,
             Spreadsheet.Row = spreadsheet_row) %>%
      select(Participant.Private.ID, Spreadsheet.Row, screen_index, time_stamp, type,
             face_conf, x_pred_normalised, y_pred_normalised, et_file) %>%
      group_by(Participant.Private.ID, et_file) %>%
      mutate(time = time_stamp - min(time_stamp)) %>%
      ungroup()  # Ungroup to avoid grouped output issues
    
    # Add the processed data to the list
    all_data <- append(all_data, list(combined_data))
  }

  # Combine all processed data into a single dataframe
  final_data <- bind_rows(all_data)
  
  return(final_data)
}

# Define the base path
path <- "../extension_data"

# Pattern for filtering files in the 'uploads' subfolders
pattern_et <- "ci6a|rkna|3ud8|4nzj"

# Combine and process the ET files
et_data <- combine_et_files_by_pattern(directories, pattern_et)

library(conflicted)
et_data<-et_data%>%filter(type=="prediction")
# Write the combined ET data to a CSV file
write.csv(et_data, "../data_syb/combined_et_data_extension.csv", row.names = FALSE)
```

```{r}
# Reading the data back from the saved CSV files
et_data <- read.csv("../data_syb/combined_et_data_extension.csv")
test_data <- read.csv("../data_syb/test_data_extension.csv")
train_data <- read.csv("../data_syb/train_data_extension.csv")
quest_data <- read.csv("../data_syb/quest_extension.csv")
audio_data <- read.csv("../data_syb/audio_lengths.csv")
```

```{r}
#language questionnaire
lang_quest<-quest_data%>%
  select(Participant.Private.ID,Question,Object.Name,
         Object.Number,Object.ID,Response.Type,Key,Response,randomiser.ggy2)%>%
  filter(Response!="BEGIN"&Response!="END",Key != "quantised")%>%
  mutate_all(~gsub('-', "_", .))%>%
  mutate_all(~gsub('-', "_", .))%>%
  mutate_all(~gsub('Mandarin Chinese', "Mandarin", .))%>%
  mutate_all(~gsub('Chinese', "Mandarin", .))

basic_background<-lang_quest%>%
  filter(Object.Name=="age"|
         Object.Name=="gender"|
         Object.Name=="education"|
         Object.Name=="mother_education"|
         Object.Name=="father_education"|
         Object.Name=="number_of_langs")%>%
  select(Participant.Private.ID,Object.Name,Response)%>%
  pivot_wider(names_from = Object.Name,values_from = Response)%>%
  mutate_all(~gsub('c\\("__other", "', "", .))%>%
  mutate_all(~gsub('"\\)', "", .))%>%
  mutate_all(~gsub(' languages', "", .))%>%
  mutate_all(~gsub(' language', "", .))%>%
  mutate_all(~gsub('Graduate _ ', "", .))%>%
  mutate_all(~gsub('College _ ', "", .))

linguistic_background<-lang_quest%>%
  filter(Object.Name!="age"&
         Object.Name!="gender"&
         Object.Name!="education"&
         Object.Name!="mother_education"&
         Object.Name!="father_education"&
         Object.Name!="number_of_langs")%>%
  select(Participant.Private.ID,Object.Name,Response)
  
dom_acqu<-linguistic_background%>%
  filter(grepl("order", Object.Name, ignore.case = TRUE))%>%
  mutate(first_char = substr(Object.Name, 1, 1),
         rest_of_name = substr(Object.Name, 2, nchar(Object.Name)))%>%
  group_by(Participant.Private.ID,rest_of_name) %>%
  mutate(item_count = row_number(),
         item=paste(rest_of_name,"_",item_count,sep = ""))%>%
  ungroup()%>%
  select(Participant.Private.ID, item,Response)%>%
  pivot_wider(names_from = item, values_from=Response)

dom_acqu <- dom_acqu %>%
  rowwise() %>%
  select(Participant.Private.ID, order(names(.)))%>%
  mutate(list_o_all_langs = paste(c_across(2:(ncol(dom_acqu)-1)), collapse = ","))

ordering_lang<-linguistic_background%>%
  filter(!grepl("order", Object.Name, ignore.case = TRUE))%>%
  pivot_wider(names_from = Object.Name, values_from=Response)%>%
  mutate(language1=paste(language1,`1lang_english_check`,sep=""))%>%
  mutate_all(~gsub('NA', "", .))

lang_group<-lang_quest%>%
  select(Participant.Private.ID,randomiser.ggy2)%>%
  unique()

language_condition_quest<-train_data%>%
  select(Participant.Private.ID,Spreadsheet.Name)%>%
  mutate(language_condition = sub(".*_", "", Spreadsheet.Name))%>%
  select(-Spreadsheet.Name)%>%
  unique()%>%
  na.omit()%>%
  mutate(Participant.Private.ID=as.character(Participant.Private.ID))


lang_back<-basic_background%>%
  left_join(dom_acqu)%>%
  left_join(ordering_lang)%>%
  mutate(monolingual=if_else(is.na(`1lang_english_check`),0,1))%>%
  select(!`1lang_english_check`)%>%
  mutate(first_lang_is_lang=if_else(language1 ==lang_acquisition_order_1,1,0),
         second_lang_is_lang=if_else(language2 ==lang_acquisition_order_2,1,0),
         first_dom_is_lang=if_else(language1 ==lang_dominance_order_1,1,0),
         second_dom_is_lang=if_else(language2 ==lang_dominance_order_2,1,0))%>%
  mutate(lang_acquisition_order_1=if_else(monolingual==1,language1,lang_acquisition_order_1),
         lang_dominance_order_1=if_else(monolingual==1,language1,lang_dominance_order_1))%>%
  mutate(lang_acquisition_order_2=if_else(monolingual==1,"none",lang_acquisition_order_2),
         lang_dominance_order_2=if_else(monolingual==1,"none",lang_dominance_order_2))%>%
  ungroup()%>%
  left_join(lang_group)%>%
  left_join(language_condition_quest)%>%
  mutate(age=as.numeric(age))


overall_mean_age <- mean(lang_back$age)
overall_sd_age <- sd(lang_back$age)

# Group and calculate both group-specific and overall statistics
aggs_quest <- lang_back %>%
  group_by(language_condition, randomiser.ggy2) %>%
  summarize(
    mean_age = mean(age),
    sd_age = sd(age),
    min_age = min(age),
    max_age = max(age))%>%
  mutate(overall_mean_age = overall_mean_age,
         overall_sd_age = overall_sd_age)


ggplot(aggs_quest, aes(x = interaction(language_condition, randomiser.ggy2), y = mean_age)) +
  geom_point(size = 3) + 
  geom_errorbar(aes(ymin = mean_age - sd_age, ymax = mean_age + sd_age), width = 0.2) +
  geom_hline(yintercept = overall_mean_age, linetype = "dashed", color = "red", size = 1) +
  geom_text(aes(x = 3.5, y = overall_mean_age, label = paste("Overall Mean:", round(overall_mean_age, 2)),alpha=.4), 
            vjust = -1, color = "red") + 
  geom_text(aes(label = paste("Min:", min_age), y = min_age), vjust = 1.5, color = "blue") + 
  geom_text(aes(label = paste("Max:", max_age), y = max_age), vjust = 1.5, color = "blue") + 
  labs(title = "Mean Age per Group with SD, Min, and Max",
       x = "Group (language_condition x randomiser)",
       y = "Mean Age") +
  geom_point(aes(y = min_age), color = "blue", alpha = 0.5, size = 2) +
  geom_point(aes(y = max_age), color = "blue", alpha = 0.5, size = 2)+
  theme_minimal() -> age

ggsave(filename = "visualizations/questionnaire_visualizations/age.png",plot = age,width = 10,height = 6,dpi = 300)


# Clean up numeric ratings and selectively handle NAs
quest_agg2 <- lang_back %>%
  mutate(
    # Clean up language proficiency scores and age_start_learning
    l1_speaking_score = as.numeric(sub(" _.*", "", l1_speaking)),
    l1_comprehension_score = as.numeric(sub(" _.*", "", l1_comprehension)),
    l1_age_start_learning = as.numeric(l1_age_start_learning),
    l2_speaking_score = as.numeric(sub(" _.*", "", l2_speaking)),
    l2_comprehension_score = as.numeric(sub(" _.*", "", l2_comprehension)),
    l2_age_start_learning = as.numeric(l2_age_start_learning),
    l3_speaking_score = as.numeric(sub(" _.*", "", l3_speaking)),
    l3_comprehension_score = as.numeric(sub(" _.*", "", l3_comprehension)),
    l3_age_start_learning = as.numeric(l3_age_start_learning),
    l4_speaking_score = as.numeric(sub(" _.*", "", l4_speaking)),
    l4_comprehension_score = as.numeric(sub(" _.*", "", l4_comprehension)),
    l4_age_start_learning = as.numeric(l4_age_start_learning),
    l5_speaking_score = as.numeric(sub(" _.*", "", l5_speaking)),
    l5_comprehension_score = as.numeric(sub(" _.*", "", l5_comprehension)),
    l5_age_start_learning = as.numeric(l5_age_start_learning)
  ) %>%
  select(Participant.Private.ID, monolingual, randomiser.ggy2, language_condition,
         l1_speaking_score, l1_comprehension_score, l1_age_start_learning,
         l2_speaking_score, l2_comprehension_score, l2_age_start_learning,
         l3_speaking_score, l3_comprehension_score, l3_age_start_learning,
         l4_speaking_score, l4_comprehension_score, l4_age_start_learning,
         l5_speaking_score, l5_comprehension_score, l5_age_start_learning) %>%
  mutate(across(ends_with("speaking_score"):ends_with("comprehension_score"), ~ replace_na(., 0)))

quest_agg2_long <- quest_agg2 %>%
  pivot_longer(
    cols = c(starts_with("l1"), starts_with("l2"), starts_with("l3"), 
             starts_with("l4"), starts_with("l5")),  # Pivot language columns
    names_to = c("language", "attribute"),
    names_pattern = "(l\\d)_(speaking|comprehension|age_start_learning)",  # Remove _score
    values_to = "score"
  ) %>%
  filter(!is.na(score))
  


lang_Xs<-ggplot(quest_agg2_long%>%
                  filter(attribute=="age_start_learning",language!="l1"), aes(x = language, y = score, group = interaction(Participant.Private.ID,language), color = language)) +
  geom_jitter() +
  labs(
    title = "Participant Scores Across Languages and Attributes",
    x = "Attribute (Speaking, Comprehension, Age Start Learning)",
    y = "Age started learning additional languages",
    color = "Language") +
  theme_minimal()

ggsave(filename = "visualizations/questionnaire_visualizations/lang_Xs.png", plot = lang_Xs,width = 10,height = 6,dpi = 300)

set.seed(123)
lang_age<-ggplot(quest_agg2_long%>%filter(attribute!="age_start_learning"), aes(x = attribute, y = score, group = interaction(Participant.Private.ID,language), color = language)) +
  geom_point(position = position_jitter(width = 0.5, height = 0.5)) +
  labs(
    title = "Participant Scores Across Languages and Attributes",
    x = "Attribute (Speaking, Comprehension, Age Start Learning)",
    y = "Score for speaking and comprehension",
    color = "Language") +
  theme_minimal()
ggsave(filename = "visualizations/questionnaire_visualizations/lang_age.png", plot = lang_age,width = 10,height = 6,dpi = 300)

#participant with high L2 score is an L2 Swahili speaker in the Mandarin condition. Because the fricatives do not overlap we do not expect this to be an issue. We will proceeed without removal because they said that English was their first and most dominant language with high accent percent in their L2 in accoradance with Finding the Native Speakers by Brown and Colleagues: https://doi.org/10.1017/S0142716423000064
```

```{r}
attention<-train_data%>%
  select(Participant.Private.ID,Spreadsheet.Name,Response,image,image_1:image_3,display,sound_stimuli,audio_1,audio_2,audio_3,Screen.Name,Zone.Name,Zone.Type,tester_1:tester_3)%>%
  filter(str_detect(display, "test"))%>%
  filter(Screen.Name=="Screen 6")%>%
  filter(Zone.Type == "response_keyboard_single"|Zone.Type == "response_button_image")%>%
  mutate(participant_response=case_when(Response==1&str_detect(display, "test_sound")~tester_1,
                                   Response==2&str_detect(display, "test_sound")~tester_2,
                                   Response==3&str_detect(display, "test_sound")~tester_3,
                                   str_detect(Response, "png")~Response))%>%
  mutate(response_correct = case_when(str_detect(display, "test_sound")&sound_stimuli==participant_response~0,
                                      str_detect(display, "test_sound")&sound_stimuli!=participant_response~1,
                                      str_detect(display, "test_image")&image==participant_response~0,
                                      str_detect(display, "test_image")&image!=participant_response~1))
  
attention_agg<-attention%>%
  group_by(Participant.Private.ID)%>%
  summarize(score=sum(response_correct))%>%
  mutate(score_normalized=(score),
         mean=mean(score_normalized),
         sd=sd(score_normalized),
         max=mean+sd*2,
         min=mean-sd*2)

attention_agg%>%ggplot(aes(x=Participant.Private.ID,y=score_normalized,color=factor(score)))+
  geom_point()+
  geom_hline(aes(yintercept = mean))+
  geom_hline(aes(yintercept = max))+
  geom_hline(aes(yintercept = min))
attention_agg%>%ggplot(aes(x=Participant.Private.ID,y=score,color=factor(score)))+
  geom_point()+
  geom_hline(aes(yintercept = mean))+
  geom_hline(aes(yintercept = max))+
  geom_hline(aes(yintercept = min))


remove_attention_agg<-attention_agg%>%filter(score>=3)
keep_attention_agg<-attention_agg%>%filter(score<3)
nrow(remove_attention_agg)
nrow(keep_attention_agg)
```

```{r}
image_1_m<-c("phe_fo","o_lc")
image_2_m<-c("o_ho","tshe_r")
image_3_m<-c("tshe_lo","phe_hc")
image_1_c<-c("sh_ao","ji_ou")
image_2_c<-c("zh_ou","qi_ang")
image_3_c<-c("ch_ang","xi_ao")
image_1_k<-c("p_al","b_ul")
image_2_k<-c("p_ul","b_at")
image_3_k<-c("p_at","b_al")
image_1_j<-c("h_eeya","t_ori")
image_2_j<-c("t_oori","sh_iku")
image_3_j<-c("sh_iiku","h_eya")

# Combine the different image sets into single vectors
image_1 <- c(image_1_m, image_1_c, image_1_k, image_1_j)
image_2 <- c(image_2_m, image_2_c, image_2_k, image_2_j)
image_3 <- c(image_3_m, image_3_c, image_3_k, image_3_j)

test_data$randomiser.ggy2
# Now update the test_data processing
test_data_cleaned <- test_data %>%
  filter(Participant.Private.ID %in% keep_attention_agg$Participant.Private.ID) %>%
  select(Participant.Private.ID, Spreadsheet.Name, Reaction.Time, Screen.Name, Zone.Name, Response, Reaction.Time, image, audio_1, audio_2, audio_3, stimulus, randomise_trials, frequency, segment, image, Trial.Number,randomiser.ggy2,Zone.Type)%>%
  filter(randomise_trials == 4)%>%
  filter(Screen.Name == "Screen 5")%>%
  filter(Zone.Type == "response_keyboard_single")%>%
  mutate(
    selected_stimulus = case_when(
      Response == 2 ~ audio_1,
      Response == 1 ~ audio_2,
      Response == 3 ~ audio_3
    ),
    match_stimulus = case_when(
      selected_stimulus %in% paste0(image_1, "2.mp3") | selected_stimulus %in% paste0(image_1, ".mp3") ~ "bluesquare.png",
      selected_stimulus %in% paste0(image_2, "2.mp3") | selected_stimulus %in% paste0(image_2, ".mp3") ~ "redcircle.png",
      selected_stimulus %in% paste0(image_3, "2.mp3") | selected_stimulus %in% paste0(image_3, ".mp3") ~ "yellowtriangle.png"
    ),
    correct = if_else(stimulus == selected_stimulus, 1, 0),
    language = Spreadsheet.Name,
    order.pattern = randomiser.ggy2
  )

#participant removal  
participant_medians <- test_data_cleaned %>%
  mutate(norm_rt = log(Reaction.Time)) %>%
  group_by(Participant.Private.ID) %>%
  summarise(median_rt = median(norm_rt),
            MAD = mad(norm_rt)) %>%
  ungroup()

# Step 2: Compute the MAD of median_rt across all participants
overall_median_rt <- median(participant_medians$median_rt)
overall_MAD <- mad(participant_medians$median_rt)

# Step 3: Create the upper and lower MAD thresholds across participants
participant_medians <- participant_medians %>%
  mutate(upper_MAD = overall_median_rt + 3 * overall_MAD,
         lower_MAD = overall_median_rt - 3 * overall_MAD)


# Step 4: Filter based on these thresholds
test_data_cleaned <- participant_medians %>%
  left_join(test_data_cleaned, by = "Participant.Private.ID") %>%
  filter(Reaction.Time > 200) %>%
  mutate(trial_rounded = round(as.numeric(Trial.Number) / 10) * 10,
         test = sub("^(test_[0-9]+)_.*", "\\1", language),
         language = gsub("test_[0-9]+_", "", language))

ggplot(participant_medians, aes(x = Participant.Private.ID, y = median_rt)) +
  geom_point(color = "blue", size = 3) +  # Plot median reaction times for each participant
  geom_hline(aes(yintercept = median(median_rt)), color = "green", linetype = "dashed", size = 1) +  # Median line
  geom_hline(aes(yintercept = upper_MAD), color = "red", linetype = "dashed", size = 1) +  # Upper MAD line
  geom_hline(aes(yintercept = lower_MAD), color = "red", linetype = "dashed", size = 1) +  # Lower MAD line
  labs(title = "Participants' Median Reaction Times with MAD Boundaries",
       x = "Participant",
       y = "Log of Median Reaction Time") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 



length(unique(test_data_cleaned$Participant.Private.ID))
before_rem<-nrow(test_data_cleaned)

#kitems removal
test_data_cleaned<-test_data_cleaned%>%
  filter(Reaction.Time>200)%>%
  mutate(norm_rt=log(Reaction.Time),
         median_rt=median(norm_rt),
         normal_rt=abs(median_rt-norm_rt))%>%
  mutate(MAD=sum(normal_rt)/n(),
         upper_MAD=MAD*3+median_rt,
         lower_MAD=median_rt-MAD*3)%>%
  filter(norm_rt>lower_MAD & norm_rt<upper_MAD)%>%
  mutate(trial_rounded = round(as.numeric(Trial.Number)/10) * 10)%>%
  mutate(test = sub("^(test_[0-9]+)_.*", "\\1", language),
    language = gsub("test_[0-9]+_", "", language))

after_rem<-nrow(test_data_cleaned)
before_rem-after_rem
(before_rem-after_rem)/before_rem

test_data_cleaned%>%ggplot(aes(x=Reaction.Time,fill=as.factor(Participant.Private.ID)))+
  geom_density(position = 'identity',alpha=.5)+
  theme_minimal() +
  theme(legend.position = "none")
```

```{r}
test_data_agg<-test_data_cleaned%>%
  mutate(frequency=as.factor(frequency),
         Participant.Private.ID=as.factor(Participant.Private.ID),
         Spreadsheet.Name=as.factor(Spreadsheet.Name))%>%
  dplyr::group_by(Participant.Private.ID,frequency,language,order.pattern)%>%
  dplyr::summarize(score=mean(correct))%>%
  mutate(group=if_else(order.pattern=="image_first",1,0))


test_data_agg%>%
  ggplot()+
  geom_jitter(aes(x=interaction(frequency,order.pattern),y=score,color=frequency),size=3)+

  geom_boxplot(aes(x=interaction(frequency,order.pattern),y=score,fill=frequency),alpha=.2,width=.1)+
  theme_minimal()+
  geom_hline(yintercept=.33, linetype="dashed", color = "black")+
  scale_y_continuous(limits = c(-0.2, 1.2))+
  facet_grid(.~language)
  
test_data_agg%>%filter(language!="korean")%>%
  ggplot()+
  geom_dotplot(aes(x=interaction(frequency,order.pattern),y=score,fill=frequency),
               binaxis = "y", stackdir = "center")+
  geom_boxplot(aes(x=interaction(frequency,order.pattern),
                  y=score,
                  color=frequency),
              alpha=.2,width=.5,fill="white")+
  geom_line(aes(x=interaction(frequency, order.pattern), 
                y=score, 
                group=Participant.Private.ID), 
            color="black", size=0.5, alpha=0.5)+
  theme_minimal()+
  geom_hline(yintercept=.33, linetype="dashed", color = "black")+
  scale_y_continuous(limits = c(0, 1))+
  scale_fill_manual(values = c("#C41230", "#043673"))+
  scale_color_manual(values = c("#C41230", "#043673"))+
  facet_grid(language~.)

existing_files <- list.files("visualizations/")
base_filename <- "accuracy_connect_participant"
new_filename <- paste0(base_filename, length(existing_files), ".png")
ggsave(filename = paste0("visualizations/", new_filename), plot = last_plot(), width = 8, height = 6)

test_data_agg%>%filter(language!="korean")%>%
  ggplot()+
  geom_dotplot(aes(x=interaction(frequency,order.pattern),y=score,fill=frequency),
               binaxis = "y", stackdir = "center",alpha=.3)+
  geom_violin(aes(x=interaction(frequency,order.pattern),
                  y=score,
                  fill=frequency,
                  color=frequency),
              alpha=.2,width=2)+
  geom_boxplot(aes(x=interaction(frequency,order.pattern),
                  y=score,
                  color=frequency),
              alpha=.2,width=.05,fill="white")+
  theme_minimal()+
  geom_hline(yintercept=.33, linetype="dashed", color = "black")+
  scale_y_continuous(limits = c(0, 1))+
  scale_fill_manual(values = c("#C41230", "#043673"))+
  scale_color_manual(values = c("#C41230", "#043673"))+
  facet_grid(.~language)

base_filename <- "accuracy_by_participant"
new_filename <- paste0(base_filename, length(existing_files), ".png")
ggsave(filename = paste0("visualizations/", new_filename), plot = last_plot(), width = 8, height = 6)

test_data_agg1<-test_data_cleaned%>%
  mutate(frequency=as.factor(frequency),
         Participant.Private.ID=as.factor(Participant.Private.ID),
         Spreadsheet.Name=as.factor(order.pattern))%>%
  dplyr::group_by(order.pattern,frequency,language)%>%
  dplyr::summarize(score=mean(correct))%>%
  mutate(group=if_else(order.pattern=="image_first",1,0))%>%
  filter(language!="korean")

test_data_agg1%>%
  ggplot()+
  geom_point(aes(x=interaction(order.pattern),y=score,color=frequency,fill=language,alpha=.1,size=3))+
  theme_minimal()+
  geom_hline(yintercept=.33, linetype="dashed", color = "black")+
  scale_y_continuous(limits = c(0.0, 1))+
  facet_grid(.~language)

base_filename <- "accuracy_overall"
new_filename <- paste0(base_filename, length(existing_files), ".png")
ggsave(filename = paste0("visualizations/", new_filename), plot = last_plot(), width = 8, height = 6)
```

```{r}

# Function to compare models for a specific language and return the best model based on AIC
compare_models <- function(data, frequency_var, id_var, image_var, correct_var, spreadsheet_name_var) {
  
  # Helper function to fit model and catch errors or convergence warnings
  safe_glmer <- function(formula, data) {
    tryCatch(
      {
        glmer(formula, family = binomial, data = data, 
              control = glmerControl(optCtrl = list(maxfun = 100000)))
      },
      error = function(e) {
        return(NULL)  # Return NULL if the model fails
      },
      warning = function(w) {
        return(NULL)  # Return NULL if there's a warning like non-convergence
      }
    )
  }

  # Model 1: Complex
  m1_formula <- as.formula(paste(correct_var, "~", frequency_var, "*", spreadsheet_name_var, "+ (", image_var, "|", id_var, ")"))
  m1 <- safe_glmer(m1_formula, data)
  
  # Model 2: Reduced random effects
  m2_formula <- as.formula(paste(correct_var, "~", frequency_var, "*", spreadsheet_name_var, "+ (", image_var, "||", id_var, ")"))
  m2 <- safe_glmer(m2_formula, data)
  
  # Model 3: Simplified random effects
  m3_formula <- as.formula(paste(correct_var, "~", frequency_var, "*", spreadsheet_name_var, "+ (1|", id_var, ")"))
  m3 <- safe_glmer(m3_formula, data)


  # Collect models and filter out the ones that failed
  models <- list(m1, m2, m3)
  models <- models[!sapply(models, is.null)]  # Remove NULL models

  # Compare models and select the best one based on AIC
  if (length(models) > 0) {
    bic_values <- sapply(models, BIC)  # Use BIC instead of AIC
    best_model <- models[[which.min(bic_values)]]
    return(best_model)
  } else {
    return("No models converged.")
  }
}


recode_and_reorder <- function(data) {
  # Rename levels for Spreadsheet.Name
  levels(data$Spreadsheet.Name) <- c("Non-discriminative", "Discriminative")
  
  # Rename levels for frequency
  levels(data$frequency) <- c("Low","High")
  
  #Reorder factor levels so that Non-discriminative is the baseline for Spreadsheet.Name
  data$Spreadsheet.Name <- factor(data$Spreadsheet.Name, levels = c("Non-discriminative","Discriminative"))
  
  # Reorder factor levels so that High is the baseline for frequency
  data$frequency <- factor(data$frequency, levels = c("High","Low"))
  
  return(data)
}


model_data_c<-test_data_cleaned%>%
  filter(language=="mandarin")%>%
  mutate(frequency=as.factor(frequency),
         Spreadsheet.Name=as.factor(randomiser.ggy2))
model_data_m<-test_data_cleaned%>%
  filter(language=="minnan")%>%
  mutate(frequency=as.factor(frequency),
         Spreadsheet.Name=as.factor(randomiser.ggy2))
model_data_j<-test_data_cleaned%>%
  filter(language=="japanese")%>%
  mutate(frequency=as.factor(frequency),
         Spreadsheet.Name=as.factor(randomiser.ggy2))
```

```{r}

# Apply the function to each dataset
model_data_c <- recode_and_reorder(model_data_c)
model_data_j <- recode_and_reorder(model_data_j)
model_data_m <- recode_and_reorder(model_data_m)

# Check the levels (optional)
levels(model_data_c$Spreadsheet.Name)
levels(model_data_c$frequency)
levels(model_data_j$Spreadsheet.Name)
levels(model_data_j$frequency)
levels(model_data_m$Spreadsheet.Name)
levels(model_data_m$frequency)

# Check the levels to
# Run the comparison for each language and store the best models
best_model_mandarin <- compare_models(model_data_c, "frequency", "Participant.Private.ID", "image", "correct", "Spreadsheet.Name")
best_model_japanese <- compare_models(model_data_j, "frequency", "Participant.Private.ID", "image", "correct", "Spreadsheet.Name")
best_model_minnan <- compare_models(model_data_m, "frequency", "Participant.Private.ID", "image", "correct", "Spreadsheet.Name")

summary(best_model_mandarin)
summary(best_model_japanese)
summary(best_model_minnan)
```

```{r}
# Function to extract coefficients and confidence intervals
extract_coef_with_confint <- function(model, model_name) {
  # Extract confidence intervals
  conf_int <- confint(model, method = "Wald", parm = "beta_")
  conf_int_df <- as.data.frame(conf_int)
  conf_int_df$Term <- rownames(conf_int_df)
  
  # Extract fixed effects (coefficients)
  fixed_effects_df <- as.data.frame(fixef(model), row.names = NULL)
  names(fixed_effects_df) <- c("Estimate")
  fixed_effects_df$Term <- rownames(fixed_effects_df)
  
  # Extract p-values
  p_vals <- summary(model)$coefficients[, "Pr(>|z|)"]
  p_vals_df <- as.data.frame(p_vals)
  p_vals_df$Term <- rownames(p_vals_df)
  
  # Merge all the information into a single dataframe
  coef_df <- merge(fixed_effects_df, conf_int_df, by = "Term")
  coef_df <- merge(coef_df, p_vals_df, by = "Term")
  
  coef_df$model <- model_name
  
  return(coef_df)
}

# Function to get predictions
generate_predictions <- function(model_data, model, model_name) {
  # Create new data for prediction
  newData <- expand.grid(
    Spreadsheet.Name = unique(model_data$Spreadsheet.Name),
    frequency = unique(model_data$frequency)
  )
  
  # Get predicted probabilities
  newData$predictedProbability <- predict(model, newdata = newData, type = "response", re.form = NA)
  
  # Reverse the factor levels of Spreadsheet.Name
  newData$Spreadsheet.Name <- fct_rev(newData$Spreadsheet.Name)
  
  # Add a column for the model name (language)
  newData$model <- model_name
  
  return(newData)
}

# Extract coefficients and predictions for all best models
coef_mandarin <- extract_coef_with_confint(best_model_mandarin, "Mandarin")
coef_japanese <- extract_coef_with_confint(best_model_japanese, "Japanese")
coef_minnan <- extract_coef_with_confint(best_model_minnan, "Minnan")
coef_nixon <- data.frame(
  Term = c("(Intercept)", "frequencyLow", "frequencyLow:Spreadsheet.NameDiscriminative", 
           "Spreadsheet.NameDiscriminative"),
  Estimate = c(NA, NA, NA, NA),
  `2.5 %` = NA,
  `97.5 %` = NA,
  Model = "Nixon (2020)"
)

# Combine coefficient data into a single dataframe
all_coef_df <- bind_rows(coef_mandarin, coef_japanese, coef_minnan)


# Generate predictions for each best model
predictions_mandarin <- generate_predictions(model_data_c, best_model_mandarin, "Mandarin")
predictions_japanese <- generate_predictions(model_data_j, best_model_japanese, "Japanese")
predictions_minnan <- generate_predictions(model_data_m, best_model_minnan, "Minnan")
predictions_nixon <- data.frame(
  Spreadsheet.Name = c("Discriminative", "Non-discriminative", "Discriminative", "Non-discriminative"),
  frequency = c("Low", "Low", "High", "High"),
  predictedProbability = c(.66, .375, .98, .99), # You can fill these in later
  model = "Nixon (2020) Southernn Min"
)

# Combine predictions into one dataframe
all_predictions <- bind_rows(predictions_mandarin, predictions_japanese, predictions_minnan,predictions_nixon)
```

```{r}
nixon_insp_mod<-ggplot(all_predictions, aes(x = Spreadsheet.Name, y = predictedProbability, group = frequency, color = Spreadsheet.Name,size=frequency,linewidth=frequency)) +
  geom_line(color="#e0e0e0",alpha=.5) +  # Apply dodging to lines
  geom_point() +  # Apply dodging to points
  labs(x = "", y = "Predicted Probability", color = "Condition",size = "Frequency") +
  facet_grid(~model,labeller = labeller(model = c(
    "Japanese" = "Japanese\n", 
    "Mandarin" = "Mandarin\n", 
    "Minnan" = "Southern Min\n",
    "Nixon (2020) Southernn Min" = "Southernn Min\nNixon (2020) "))) + 
  theme_minimal() +
  scale_color_manual(values = c("#043673", "#FDB515"))+
  scale_size_manual(values = c(6, 2)) + 
  scale_linewidth_manual(values = c(3, 1),guide = "none")+
  theme(legend.position="bottom",
        legend.direction = "horizontal")


nixon_insp_mod

ggsave(filename = "visualizations/nixon_insp_mod.png",plot = nixon_insp_mod,width = 10,height = 5,dpi = 300)

# Add significance stars based on p-values
all_coef_df <- all_coef_df %>%
  mutate(p_value_star = case_when(
    p_vals < 0.001 ~ "***",
    p_vals < 0.01 ~ "**",
    p_vals < 0.05 ~ "*",
    TRUE ~ ""
  ))

# Create the coefficient plot with significance stars
mod_out_train <- ggplot(all_coef_df, aes(x = Term, y = Estimate, color = model)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = `2.5 %`, ymax = `97.5 %`), 
                width = 0.2, position = position_dodge(width = 0.5)) +
  coord_flip() +
  geom_hline(yintercept = 0, linetype = "dotted", color = "black", size = 1) +
  geom_text(aes(x = Term, y = Estimate - 0.1, label = p_value_star,color = model), 
            hjust = 1.4,vjust = .4, position = position_dodge(width = 0.5), size = 5,show.legend = FALSE) +  # Add stars next to points
  labs(title = "Model Coefficients by Language",
       x = "Term", y = "Coefficient Estimate") +
  theme_minimal() +
  theme(legend.position = "bottom") +
  scale_color_manual(values = c("#2e4d24", "#e98019", "#a41394"), name = "Language") +
  scale_x_discrete(name = "", labels = c(
    "(Intercept)" = "Intercept", 
    "frequencyLow" = "Frequency: Low",
    "frequencyLow:Spreadsheet.NameDiscriminative" = "Frequency: Low * Condition: Discriminative",
    "Spreadsheet.NameDiscriminative" = "Condition: Discriminative"
  ))

mod_out_train

ggsave(filename = "visualizations/mod_out_train.png",plot = mod_out_train,width = 8,height = 4,dpi = 300)
```


```{r}
combined_train_data<-train_data%>%
  filter(str_detect(Response, "xlsx"))%>%
  filter(!str_detect(Response, "https"))%>%
  mutate(et_file=Response)%>%
  mutate(language = Spreadsheet.Name,
         order.pattern = randomiser.ggy2)%>%
  mutate(test = sub("^(image|sound)_first_[0-9]+_.*", "\\1_first", language),
         language = gsub("(image|sound)_first_[0-9]+_", "", language))%>%
  select(!Response)%>%
  select(Participant.Private.ID,Trial.Number,Spreadsheet.Row,Spreadsheet.Name,sound_stimuli,image,frequency,tone,segment,image_1,image_2,image_3,et_file,randomiser.ggy2,language,test,display,Tree.Node.Key)

combined_et_data<-et_data%>%
  mutate(Participant.Private.ID=Participant.Private.ID,
         Spreadsheet.Row=Spreadsheet.Row)%>%
  select(Participant.Private.ID,Spreadsheet.Row,screen_index,time_stamp,type,
         face_conf,x_pred_normalised,y_pred_normalised,et_file)%>%
  filter(type=="prediction")%>%
  group_by(Participant.Private.ID,et_file)%>%
  mutate(time=time_stamp-min(time_stamp))%>%
  filter(face_conf>.5)
```

```{r}
et<-combined_train_data%>%
  left_join(combined_et_data)%>%
  mutate(time_rounded = round(time / 50) * 50,
         word=paste(segment,tone,sep="_"))

#make compeitor and target images
df<-combined_train_data%>%
  select(image,segment,tone,frequency,language,test)%>%
  unique()%>%
  mutate(word = paste(segment, tone, sep = "_"),
         target_image = image,
         word_diff = ifelse(language != "mandarin", 
                           sub(".*_(.*)", "\\1", word), 
                           sub("(.*)_.*", "\\1", word)),
         word_sim = ifelse(language != "mandarin", 
                            sub("(.*)_.*", "\\1", word), 
                            sub(".*_(.*)", "\\1", word))
         )%>%
  filter(language != "korean")

competitor<-df%>%
  select(image,word_sim,frequency,language,test)%>%
  pivot_wider(names_from = frequency,names_prefix = "freq_",values_from = image)


competitor1<-competitor%>%
  mutate(target_image=freq_10,
         distractor_image=freq_30)

competitor2<-competitor%>%
  mutate(target_image=freq_30,
         distractor_image=freq_10)

key_competitors<-rbind(competitor1,competitor2)%>%
  select(!c(freq_10,freq_30))%>%
  unique()

competitors<-key_competitors$target_image%>%unique()


comp_images<-df%>%
  left_join(key_competitors)%>%
  mutate(nonce_image = case_when(
    !target_image %in% competitors[1] & !distractor_image %in% competitors[1] ~ competitors[1],
    !target_image %in% competitors[2] & !distractor_image %in% competitors[2] ~ competitors[2],
    TRUE ~ competitors[3]
  ))%>%
  select(word:nonce_image)%>%
  unique()

et<-et%>%left_join(comp_images)
```

```{r}
et_cats <- et %>%
  mutate(
    # Adjust points relative to the new center at (0.5, 0.5)
    adjusted_x = x_pred_normalised - 0.5,
    adjusted_y = y_pred_normalised - 0.5,
    # Calculate angle in radians from the adjusted points
    angle = atan2(adjusted_y, adjusted_x),
    # Adjust angle to rotate the frame of reference so that the positive y-axis is the starting
    angle = angle - pi/2,
    # Normalize the angle to be within the [0, 2*pi) range
    angle = ifelse(angle < 0, angle + 2*pi, angle),
    # Convert angle to degrees for easier interpretation
    angle_deg = angle * 180 / pi,
    # Categorize based on the adjusted angle
    sector = case_when(
      angle_deg < 120 ~ "bluesquare.png",
      angle_deg >= 120 & angle_deg < 240 ~ "yellowtriangle.png",
      TRUE ~ "redcircle.png" ),
    # Calculate Euclidean distance from the origin (0.5, 0.5)
    distance_from_origin = sqrt(adjusted_x^2 + adjusted_y^2),
    target_looks = if_else(sector == target_image, 1, 0),
    distractor_looks = if_else(sector == distractor_image, 1, 0),
    nonce_looks = if_else(sector == nonce_image, 1, 0),
    distance_center=if_else(distance_from_origin<.1,1,0)
  )%>%
  separate(Spreadsheet.Name, into = c("type", "order", "number"), sep = "_")%>%
  mutate(order.pattern=randomiser.ggy2)%>%
  filter(x_pred_normalised>0&x_pred_normalised<1&y_pred_normalised>0&y_pred_normalised<1)

et_cats%>%filter(distance_center==0)%>%ggplot(aes(x=adjusted_x,y=adjusted_y,color=sector))+
  geom_point()+
  facet_grid(order.pattern~language)+
  theme(aspect.ratio = 1)


et_cats_agg_samp<-et_cats%>%
  group_by(language,Participant.Private.ID,type)%>%
  count()

et_cats_agg_samp%>%ggplot(aes(x=interaction(language,type),y=n,color=type))+
  geom_jitter()+
  geom_violin(alpha=.4)+
  geom_text(aes(label = Participant.Private.ID), 
            position = position_jitter(width = 0.2, height = 0.5),
            vjust = -0.5, 
            size = 3)

et_cats_agg_samp<-et_cats%>%
  group_by(language,Participant.Private.ID,type)%>%
  count()%>%
  filter(n>1000)

et_cats_agg_samp%>%ggplot(aes(x=interaction(language,type),y=n,color=type))+
  geom_jitter()+
  geom_violin(alpha=.4)+
  geom_text(aes(label = Participant.Private.ID), 
            position = position_jitter(width = 0.2, height = 0.5),
            vjust = -0.5, 
            size = 3)
```

```{r}
et_agg<-et_cats%>%
  left_join(audio_data, by = c("sound_stimuli" = "file_name"))%>%
  filter(Participant.Private.ID %in% et_cats_agg_samp$Participant.Private.ID)%>%
  #filter(Participant.Private.ID %in% keep_attention_agg$Participant.Private.ID)
  filter(distance_center==0)%>%
  group_by(type,time_rounded,frequency,distance_center,language)%>%
  mutate(time_rounded=time_rounded-200)%>%
  summarize(looks_target=mean(target_looks),
            looks_competitor=mean(distractor_looks),
            looks_nonce=mean(nonce_looks),
            audio_length_mean_end=mean(length_ms)+1500)%>%
    mutate(audio_length_mean_end = if_else(type == "image", audio_length_mean_end+1200+ 800, audio_length_mean_end)) %>%
  mutate(audio_begin=if_else(type == "image",1500+800+1200,1500),
         image_start=if_else(type == "image",1500,audio_length_mean_end+1200),
         image_end=image_start+800)%>%

  #mutate(time_rounded=if_else(type=="image",time_rounded+1700,time_rounded))#1200
  filter(time_rounded<4000)%>%
  filter(time_rounded>1500)%>%
  #filter(time_rounded<7000)%>%
  #mutate(time_rounded-200)%>%
  pivot_longer(col=c(looks_target:looks_nonce),names_to="looks",values_to = "values")


et_agg %>%
  ggplot(aes(y = values, 
             x = time_rounded, 
             color = interaction(looks),
             fill = as.factor(looks))) +
  geom_rect(aes(xmin = audio_begin, xmax = audio_length_mean_end, ymin = -Inf, ymax = Inf), 
            fill = "#FDB515",color=NA, alpha = 0.01) +  # Gray for audio period
  geom_rect(aes(xmin = image_start, xmax = image_end, ymin = -Inf, ymax = Inf), 
            fill = "#009647",color=NA, alpha = 0.01) +
  geom_point()+
  #geom_line(aes(group = interaction(looks, frequency))) +
  geom_smooth(se=FALSE)+
  
  facet_grid(frequency~interaction(type))+
  theme_minimal()+
  scale_color_manual(values = c("black","#182C4B", "#941120")) +
  scale_fill_manual(values = c("black","#182C4B", "#941120"))+
  facet_grid(interaction(type,frequency)~language)

```

```{r}

et_agg_t_c<-et_agg %>% filter(looks!="looks_nonce")

et_agg_t_c%>%
  ggplot(aes(y = values, 
             x = time_rounded, 
             color = interaction(looks),
             fill = as.factor(looks))) +
  geom_rect(aes(xmin = audio_begin, xmax = audio_length_mean_end, ymin = -Inf, ymax = Inf), 
            fill = "#FDB515",color=NA, alpha = 0.01) +  # Gray for audio period
  geom_rect(aes(xmin = image_start, xmax = image_end, ymin = -Inf, ymax = Inf), 
            fill = "#009647",color=NA, alpha = 0.01) +
  geom_point()+
  #geom_line(aes(group = interaction(looks, frequency))) +
  geom_smooth(se=FALSE)+
  theme_minimal()+
  scale_color_manual(values = c("#182C4B", "#941120")) +
  scale_fill_manual(values = c("#182C4B", "#941120"))+
  facet_grid(frequency~interaction(type,language))


et_agg_t_c_wider<-et_agg_t_c%>%
  mutate(values=values-.33)%>%
  pivot_wider(names_from = looks,values_from = values)%>%
  mutate(prediction_error=(looks_competitor-looks_target))

et_agg_t_c_wider%>%
  ggplot(aes(y = prediction_error, 
             x = time_rounded, 
             color = interaction(type),
             fill = as.factor(type))) +
  geom_rect(aes(xmin = audio_begin, xmax = audio_length_mean_end, ymin = -.7, ymax = -.6), 
            color = NA,fill="#FDB515", alpha = 0.01) +  # Gray for audio period
  geom_rect(aes(xmin = image_start, xmax = image_end, ymin = -.6, ymax = -.5), 
            color = NA,fill="#009647", alpha = 0.01) +
  geom_point()+
  #geom_line(aes(group = interaction(looks, frequency))) +
  geom_smooth(se=FALSE)+
  theme_minimal()+
  scale_color_manual(values = c("#182C4B", "#941120")) +
  scale_fill_manual(values = c("#182C4B", "#941120"))+
  facet_grid(frequency~interaction(language))

#et_agg_t_c%>%
#  ggplot(aes(y = values, 
#             x = time_rounded, 
#             color = interaction(frequency),
#             fill = as.factor(frequency))) +
#  geom_rect(aes(xmin = audio_begin, xmax = audio_length_mean_end, ymin = -Inf, ymax = Inf), 
#            fill = "#FDB515",color=NA, alpha = 0.01) +  # Gray for audio period
#  geom_rect(aes(xmin = image_start, xmax = image_end, ymin = -Inf, ymax = Inf), 
#            fill = "#009647",color=NA, alpha = 0.01) +
#  geom_point()+
#  #geom_line(aes(group = interaction(looks, frequency))) +
#  geom_smooth()+
#  theme_minimal()+
#  scale_color_manual(values = c("#182C4B", "#941120")) +
#  scale_fill_manual(values = c("#182C4B", "#941120"))+
#  facet_grid(looks~interaction(type,language))
```

```{r}
library(mgcv)

et_agg_t_c_mod<-et_agg_t_c%>%
  mutate(isi_begin=if_else(type=="image",image_end,audio_length_mean_end),
         isi_end=if_else(type=="sound",image_start,audio_begin))%>%
  filter(time_rounded>isi_begin)%>%
  filter(time_rounded<isi_end)%>%
  mutate(values=values-.30)%>%
  pivot_wider(names_from = looks,values_from = values)%>%
  mutate(values=(1-looks_target),
         looks="Prediction Error")
  
pe_data<-et_agg_t_c_mod%>%
  select("type","time_rounded","frequency","distance_center","language",
         "audio_length_mean_end","audio_begin","image_start",
         "image_end","values","looks")
  
et_agg_t_c_pe<-et_agg_t_c%>%
  rbind(pe_data)%>%
  mutate(type=as.factor(type),
         frequency=as.factor(frequency))

et_agg_t_c_pe <- et_agg_t_c_pe %>%
  mutate(frequency = factor(frequency, 
                       levels = c(30, 10),  # Set the order
                       labels = c("High", "Low")))

et_agg_t_c_pe <- et_agg_t_c_pe %>%
  mutate(language = factor(language, 
                           levels = c("japanese", "mandarin", "minnan"),  # Set the order
                           labels = c("Japanese", "Mandarin", "Minnan")))

et_agg_t_c_pe <- et_agg_t_c_pe %>%
  mutate(type = factor(type, 
                           levels = c("sound", "image"),  # Set the order
                           labels = c("Discriminative", "Non-discriminative")))

custom_labeller <- labeller(
  type = label_value,        # Keep the type value
  language = function(x) ""   # Remove the language label from the facet
)

pe_viz<-et_agg_t_c_pe %>%
  ggplot(aes(y = values, 
             x = time_rounded-1500, 
             color = interaction(looks),
             fill = as.factor(looks))) +
  geom_rect(aes(xmin = audio_begin-1500, xmax = audio_length_mean_end-1500, ymin = -Inf, ymax = Inf), 
            fill = "#FFBAB9", color = NA, alpha = 0.01) +  # Gray for audio period
  geom_rect(aes(xmin = image_start-1500, xmax = image_end-1500, ymin = -Inf, ymax = Inf), 
            fill = "#E0E0E0", color = NA, alpha = 0.03) +
  geom_point() +
  #geom_point(aes(y = prediction_error + 1, 
   #              x = time_rounded-1500), color = "#c41230") +  # Explicitly setting color for prediction error
  geom_smooth(se = FALSE) +
  theme_minimal() +
  scale_x_continuous(limits = c(0, 2900), breaks = seq(0, 2000, by = 500))+
  scale_color_manual(values = c("#007bc0", "#000000", "#c41230"),
                     labels = c("Looks to Competitor", "Looks to Target", "Prediction-Error"),
                     name= "") +
  scale_fill_manual(values = c("#007bc0", "#000000", "#c41230"), guide = "none") +  # Turn off the fill legend
  facet_grid(frequency ~ language + type, 
             labeller = custom_labeller)+  # Use the custom labeller
  theme(
    legend.position = "bottom",
    panel.grid.minor = element_blank(),
    strip.text.x = element_text(size = 12),  # Customize text size
    strip.background = element_blank(),  # Clean background  
    plot.margin = margin(t = 1, r = 10, b = 5, l = 10),
    axis.title.x = element_blank()  # Remove x-axis label
  ) +
  labs(x = "Time (Ms)", y = "Proportion of looks to target and Competitor with estimated prediction error", title = "                  Japanese                                                Mandarin                                           Southern Min")


pe_viz
ggsave(filename = "visualizations/pe_viz.png",plot = pe_viz,width = 10,height = 6,dpi = 300)

```


```{r}



et_agg_t_c_wider%>%
  ggplot(aes(y = prediction_error, 
             x = time_rounded, 
             color = interaction(type),
             fill = as.factor(type))) +
  geom_rect(aes(xmin = audio_begin, xmax = audio_length_mean_end, ymin = -.7, ymax = -.6), 
            color = NA,fill="#FDB515", alpha = 0.01) +  # Gray for audio period
  geom_rect(aes(xmin = image_start, xmax = image_end, ymin = -.6, ymax = -.5), 
            color = NA,fill="#009647", alpha = 0.01) +
  geom_point()+
  #geom_line(aes(group = interaction(looks, frequency))) +
  geom_smooth(se=FALSE)+
  theme_minimal()+
  scale_color_manual(values = c("#182C4B", "#941120")) +
  scale_fill_manual(values = c("#182C4B", "#941120"))+
  facet_grid(frequency~interaction(language))


```





```{r}
et_agg_t_c_mod_mod<-et_agg_t_c%>%
  mutate(isi_begin=if_else(type=="image",image_end,audio_length_mean_end),
         isi_end=if_else(type=="sound",image_start,audio_begin))%>%
  filter(time_rounded>isi_begin)%>%
  filter(time_rounded<isi_end)%>%
  mutate(values=values-.30)%>%
  pivot_wider(names_from = looks,values_from = values)%>%
  mutate(prediction_error=(1+looks_competitor-looks_target),
         looks="Prediction Error")


et_agg_t_c_mod_mod$language <- as.factor(et_agg_t_c_mod_mod$language)
et_agg_t_c_mod_mod$language <- relevel(et_agg_t_c_mod_mod$language, ref = "japanese")
levels(et_agg_t_c_mod_mod$language)

#too complex for these purposes
gam_model.1 <- gam(prediction_error ~ 
                 s(time_rounded, by = interaction(frequency)) + 
                   (factor(frequency)+type+language)*time_rounded,                            
               data = et_agg_t_c_mod_mod, family = gaussian())


gam_model <- gam(prediction_error ~ 
                 s(time_rounded, by = interaction(frequency)) + 
                   (factor(frequency)+type+language),                               # Fixed effect for look_types
               data = et_agg_t_c_mod_mod, family = gaussian())

# Summarize the model
summary(gam_model)
# Create the coefficient plot
tidy_gam <- tidy(gam_model, parametric = TRUE) %>%
  mutate(term = gsub("_", " ", term)) %>%
  mutate(term = gsub(":", " * ", term)) %>%  # Replaces interaction with *
  mutate(term = case_when(
    term == "languageminnan" ~ "Language: Southern Min",
    term == "languagemandarin" ~ "Language: Mandarin",
    term == "time_rounded" ~ "time",
    term == "typesound" ~ "Condition: Discriminative",
    term == "factor(frequency)30" ~ "Frequency: High",
    term == "factor(frequency)30:time_rounded" ~ "frequency: High*time",
    TRUE ~ term  # Default for other terms
  ))

# Add significance stars based on p-value
tidy_gam <- tidy_gam %>%
  mutate(p_value_star = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    TRUE ~ ""
  ))

# Create the coefficient plot with significance stars next to the error bars
gam_out <- ggplot(tidy_gam, aes(x = estimate, y = term)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = estimate - 1.96 * std.error, xmax = estimate + 1.96 * std.error), 
                 height = 0.2) +
  geom_text(aes(x = estimate - 1.96 * std.error, label = p_value_star), 
            hjust = 1.2, size = 5, color = "black") +  # Add stars next to CI min line
  theme_minimal() +
  labs(x = "Coefficient Estimate", y = "", title = "Coefficients of GAM Model") +
  geom_vline(xintercept = 0, linetype = "dotted", color = "black",size=1)

gam_out
ggsave(filename = "visualizations/gam_out.png",plot = gam_out,width = 8,height = 3,dpi = 300)

```



```{r}
###retrieving ISI
isi_data<-et_cats%>%
  left_join(audio_data, by = c("sound_stimuli" = "file_name"))%>%
  filter(Participant.Private.ID %in% et_cats_agg_samp$Participant.Private.ID)%>%
  #filter(Participant.Private.ID %in% keep_attention_agg$Participant.Private.ID)%>%
  filter(distance_center==0)%>%
  group_by(type,time_rounded,frequency,distance_center,language,sound_stimuli)%>%
  mutate(time_rounded=time_rounded-200)%>%
  summarize(audio_length_mean_end=mean(length_ms)+1500)%>%
    mutate(audio_length_mean_end = if_else(type == "image", audio_length_mean_end+1200+ 800, audio_length_mean_end)) %>%
  mutate(audio_begin=if_else(type == "image",1500+800+1200,1500),
         image_start=if_else(type == "image",1500,audio_length_mean_end+1200),
         image_end=image_start+800)%>%
  mutate(isi_time_begin=if_else(type=="image",image_end,audio_length_mean_end),
         isi_time_end=isi_time_begin+1200)%>%
  ungroup()%>%
  select(sound_stimuli,type,frequency,isi_time_begin,isi_time_end)%>%
  unique()

isi_predictions<-et_cats%>%
  left_join(isi_data)%>%
  mutate(s_s=if_else(Tree.Node.Key=="task-3ud8"|Tree.Node.Key=="task-ci6a",1,2))%>%
  filter(Participant.Private.ID %in% et_cats_agg_samp$Participant.Private.ID)%>%
  #filter(Participant.Private.ID %in% keep_attention_agg$Participant.Private.ID)%>%
  filter(distance_center==0)%>%
  mutate(time_rounded=time_rounded-200)%>%
  filter(time_rounded>=isi_time_begin)%>%
  filter(time_rounded<=isi_time_end)%>%
  group_by(type,frequency,distance_center,language,Participant.Private.ID,time_rounded)%>%
  summarize(looks_target=mean(target_looks),
            looks_competitor=mean(distractor_looks),
            looks_nonce=mean(nonce_looks))%>%
  mutate(prediction_error=looks_competitor-looks_target
         #Trial.Number=as.numeric(Trial.Number),
         #round_trial=round(Trial.Number/10)*10
)%>%
  group_by(type,frequency,distance_center,language,Participant.Private.ID)%>%
  summarize(prediction_error=mean(prediction_error))


pe_violin <- isi_predictions %>%
  mutate(
    frequency = recode(frequency, `10` = "Low", `30` = "High"),
    type = recode(type, `sound` = "Discriminative", `image` = "Non-discriminative"),
    language = recode(language, `japanese` = "Japanese", `mandarin` = "Mandarin", `minnan` = "Southern Min")) %>%
  ggplot(aes(x = interaction(type), y = prediction_error, linewidth = factor(frequency))) +
  geom_violin(aes(color = type,fill = type,alpha=.1)) +
  geom_boxplot(alpha=1,fill = "white",color="white",width=.2,linewidth=.3) +
  geom_boxplot(aes(fill = type, alpha=.1),color="white",width=.2,linewidth=.3) +
  geom_jitter(aes(color = type), position = position_jitter(seed = 44)) +
  geom_jitter(aes(), color = "white", size = .5, position = position_jitter(seed = 44)) +
  facet_grid(interaction(frequency) ~ interaction(language)) +
  theme_minimal() +
  scale_size_manual(values = c(3, 1, 1.5), guide = "none") + 
  scale_linewidth_manual(values = c(3, 1, 1.5), guide = "none") +  
  scale_fill_manual(values = c("#043673", "#FDB515"),guide="none") +  
  scale_color_manual(values = c("#043673", "#FDB515"),name="Condition") +  
  scale_alpha(guide = "none") +
  theme(
    strip.text = element_text(size = 12),  # Ensure facet labels are aligned and readable
    panel.spacing = unit(0.5, "lines"),  # Control space between panels
    legend.position = "top"  # Adjust legend position if needed
  )+labs(x="",y= "Mean Estimated Prediction Error")

pe_violin

ggsave(filename = "visualizations/pe_violin.png",plot = pe_violin,width = 10,height = 6,dpi = 300)

```
```{r}
isi_predictions_simp<-isi_predictions%>%select(Participant.Private.ID,frequency,language,type,prediction_error)%>%
  mutate(Participant.Private.ID=as.factor(Participant.Private.ID),
         frequency=as.factor(frequency))

test_data_agg_simp<-test_data_agg%>%
  mutate(type = sub("_.*", "", order.pattern))%>%
  mutate(Participant.Private.ID=as.factor(Participant.Private.ID),
         frequency=as.factor(frequency))

predicting_test<-test_data_agg_simp%>%
  left_join(isi_predictions_simp)

# Plot the centered data
predicting_test %>%
  ggplot(aes(x = score, y = prediction_error, color = language)) +
  geom_point() +
  facet_wrap(frequency~type) +
  theme_minimal()
```


```{r}

isi_predictions_item<-et_cats%>%
  left_join(isi_data)%>%
  mutate(s_s=if_else(Tree.Node.Key=="task-3ud8"|Tree.Node.Key=="task-ci6a",1,2))%>%
  filter(Participant.Private.ID %in% et_cats_agg_samp$Participant.Private.ID)%>%
  filter(Participant.Private.ID %in% keep_attention_agg$Participant.Private.ID)%>%
  filter(distance_center==0)%>%
  mutate(time_rounded=time_rounded-200)%>%
  filter(time_rounded>=isi_time_begin)%>%
  filter(time_rounded<=isi_time_end)%>%
  group_by(type,frequency,distance_center,language,Participant.Private.ID,sound_stimuli)%>%
  summarize(looks_target=mean(target_looks),
            looks_competitor=mean(distractor_looks),
            looks_nonce=mean(nonce_looks))%>%
  mutate(prediction_error=looks_competitor-looks_target
         #Trial.Number=as.numeric(Trial.Number),
         #round_trial=round(Trial.Number/10)*10
)


binary_prediction_error<-test_data_cleaned%>%
  select(frequency,language,
         Participant.Private.ID,stimulus,order.pattern,correct)%>%
  mutate(type = sub("_.*", "", order.pattern),
         sound_stimuli=stimulus)%>%
  mutate(Participant.Private.ID=as.factor(Participant.Private.ID),
         frequency=as.factor(frequency))%>%
  left_join(isi_predictions_item%>%
              mutate(frequency=as.factor(frequency),
                     Participant.Private.ID=as.factor(Participant.Private.ID)))

write.csv(binary_prediction_error, "../data_syb/binary_prediction_error.csv", row.names = FALSE)
binary_prediction_error<-read.csv("../data_syb/binary_prediction_error.csv")
```

```{r,eval=FALSE}
library(glmnet)
library(doParallel)

binary_prediction_error$frequency<-as.factor(binary_prediction_error$frequency)
binary_prediction_error$type <- as.factor(binary_prediction_error$type)
binary_prediction_error$language <- as.factor(binary_prediction_error$language)

binary_prediction_error$frequency <- relevel(binary_prediction_error$frequency, ref = "10")
binary_prediction_error$type <- relevel(binary_prediction_error$type, ref = "image")

run_lasso <- function(data) {
  data_filtered <- na.omit(data)
  
  # Ensure factors are correctly encoded
  data_filtered$frequency <- as.factor(data_filtered$frequency)
  data_filtered$prediction_error <- data_filtered$prediction_error
  data_filtered$type <- as.factor(data_filtered$type)
  
  # Design matrix and response variable for LASSO
  x <- model.matrix(correct ~ (prediction_error + prediction_error:frequency + prediction_error:type), data = data_filtered)[, -1]
  y <- data_filtered$correct
  
  # Define lambda search space for LASSO
  lambda_search_space <- 10^seq(2, -2, length = 100)
  
  
  # Fit LASSO regression with penalty factors
  lasso_model <- glmnet(x, y, alpha = 1, lambda = lambda_search_space, family = "binomial")
  
  # Cross-validate to find the best lambda
  cv <- cv.glmnet(x, y, alpha = 1, family = "binomial", nfolds = 10, parallel = TRUE)
  best_lambda <- cv$lambda.min
  
  # Extract coefficients at best lambda
  coef_lasso_best <- coef(lasso_model, s = best_lambda)
  coef_df <- as.data.frame(as.matrix(coef_lasso_best))
  coef_df$Predictor <- rownames(coef_df)
  rownames(coef_df) <- NULL
  
  # Visualize coefficients
  coef_plot <- ggplot(coef_df, aes(x = Predictor, y = s1)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(title = paste("LASSO Regression Coefficients at Best Lambda (", round(best_lambda, 4), ")", sep = ""),
         x = "Predictor",
         y = "Coefficient Value") +
    theme_minimal()
  print(coef_plot)
  
  # Select significant variables from LASSO
  significant_vars <- coef_df %>%
    filter(s1 != 0) %>%
    pull(Predictor)
  
  # Clean up variable names, remove intercept
  significant_vars <- significant_vars[significant_vars != "(Intercept)"]
  
  return(significant_vars)
}



run_glmm <- function(data, significant_vars) {
  data_filtered <- na.omit(data)
  
  # Clean the significant variable names (ensure random effects are not affected)
  significant_vars_clean <- gsub("30|mandarin|minnan|sound|image|10|japanese", "", significant_vars)
  
  # Prepare GLMM formula using significant variables from LASSO, and explicitly include random effects
  formula_str <- paste("correct ~", paste(significant_vars_clean, collapse = " + "), "+ (1|sound_stimuli) + (1|Participant.Private.ID)")
  
  # Convert to formula object
  formula <- as.formula(formula_str)
  
  # Fit GLMM using the selected variables and include random effects
  model_selected <- glmer(formula, data = data_filtered, family = "binomial", control = glmerControl(,optCtrl = list(maxfun = 100000)))
  
  # Print GLMM summary to check if random effects are included
  print(summary(model_selected))
  
  return(model_selected)
}

library(broom.mixed)


# Split the data into three datasets by language
binary_mandarin <- binary_prediction_error %>% filter(language == "mandarin")
binary_minnan <- binary_prediction_error %>% filter(language == "minnan")
binary_japanese <- binary_prediction_error %>% filter(language == "japanese")

# Function to run LASSO, GLMM, and return coefficients for each language
run_analysis <- function(data, language_name) {
  significant_vars <- run_lasso(data)
  model <- run_glmm(data, significant_vars)
  
  # Extract coefficients and add a language column
  coefficients_df <- tidy(model, effects = "fixed", conf.int = TRUE) %>%
    mutate(language = language_name)
  
  return(coefficients_df)
}

# Run analysis for each language
coeff_mandarin <- run_analysis(binary_mandarin, "Mandarin")
coeff_minnan <- run_analysis(binary_minnan, "Minnan")
coeff_japanese <- run_analysis(binary_japanese, "Japanese")

# Combine the coefficient dataframes
combined_coefficients <- bind_rows(coeff_mandarin, coeff_minnan, coeff_japanese)

# Create a combined coefficient plot with language coded by color
combined_coeff_plot <- ggplot(combined_coefficients, aes(x = reorder(term, estimate), y = estimate, color = language)) +
  geom_point(size = 3,position = position_dodge(width = .3)) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2,position = position_dodge(width = .3)) +
  coord_flip() +  # Flip the axes to make it horizontal
  geom_hline(yintercept = 0)+
  labs(title = "Coefficient Plot by Language",
       x = "Predictor Variables",
       y = "Estimate (with 95% CI)") +
  theme_minimal(base_size = 14)

# Print the combined plot
print(combined_coeff_plot)

```
